# A-Multimodal-Application-for-Vernacular-Language-Translation-and-Image-Synthesis
A Multimodal Application for Vernacular Language Translation and Image Synthesis

Problem Statement:
To develop a web-based application that first translates text from Tamil to English and then
uses the translated text to generate relevant images. This application aims to demonstrate the
seamless integration of language translation and creative AI to produce visual content from
textual descriptions.
Create a user-friendly, web-based application that can:
1. Translate text inputs from Tamil to English using a neural machine translation model.
2. Generate images based on the translated English text using a text-to-image model.
3. Produces creative written content based on the same or separate translated text,
enriching the multimedia content offering.
Objective:
To deploy a pre-trained or Fine tuned model using HUGGING FACE SPACES OR AWS
services, making it accessible through a web application built with Streamlit or Gradio.

Skills take away :

-- Deep Learning,
--Transformers,
--Hugging face models,
--LLM,
--Streamlit or Gradio/AWS

Results:
• Functional Web Application: A fully functional web application that users can access
to interact with the pre-trained GPT model.
• Scalable Deployment: A scalable deployment framework using Hugging Face
services services.

![Screenshot 2024-10-27 215710](https://github.com/user-attachments/assets/51f3013f-a8b4-48ed-9772-af88a1e03145)

